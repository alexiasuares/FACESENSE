# ğŸ¯ FaceSense â€“ Reconhecimento de Microgestos e Fadiga  

O **FaceSense** Ã© um projeto de pesquisa (TCC) que desenvolve um sistema inteligente para **detecÃ§Ã£o de sinais sutis de cansaÃ§o, ansiedade e inquietaÃ§Ã£o** em ambientes de estudo e trabalho.  

Ele utiliza tÃ©cnicas de **visÃ£o computacional**, **aprendizado de mÃ¡quina** e **interface humano-computador** para analisar microgestos, posturas e expressÃµes faciais em tempo real, oferecendo **feedback adaptativo** ao usuÃ¡rio para melhorar sua **produtividade, bem-estar e prevenÃ§Ã£o de fadiga**.  

---

## ğŸ” MotivaÃ§Ã£o  

Com a expansÃ£o do trabalho e estudo remoto, aumentaram os desafios relacionados Ã :  

- **Fadiga digital** (uso prolongado do computador);  
- **Ansiedade e inquietaÃ§Ã£o** durante longos perÃ­odos de concentraÃ§Ã£o;  
- **Problemas de postura e saÃºde mental** em home office;  

Poucos sistemas existentes conseguem analisar **microgestos e sinais sutis** de comportamento de forma contÃ­nua e personalizada. O **FaceSense** busca preencher essa lacuna, trazendo uma ferramenta de apoio para **autorregulaÃ§Ã£o e prevenÃ§Ã£o de burnout**.  

---

## ğŸš€ Objetivos  

- Detectar **microgestos faciais e corporais** (ex.: toques no rosto, movimentos repetitivos).  
- Identificar **expressÃµes de cansaÃ§o e fadiga** a partir de sequÃªncias temporais.  
- Fornecer **feedback em tempo real** atravÃ©s de interface interativa.  
- Apoiar usuÃ¡rios em manter **postura, foco e intervalos estratÃ©gicos**.  

---

## ğŸ§© Tecnologias Utilizadas  

- **Python 3.9+**  
- **TensorFlow / Keras** â†’ Modelagem com redes neurais LSTM  
- **Scikit-learn** â†’ Suporte ao prÃ©-processamento  
- **NumPy / Pandas** â†’ ManipulaÃ§Ã£o dos dados  
- **OpenCV + MediaPipe** â†’ Captura de vÃ­deo e landmarks em tempo real  
- **Matplotlib / Seaborn** â†’ VisualizaÃ§Ã£o de mÃ©tricas e anÃ¡lises
- **FastAPI**
- **Streamlit**

---

## ğŸ“‚ Base de Dados  

O projeto utiliza o **iMiGUE Dataset** (University of Oulu), composto por:  
- **Skeleton data** (juntas corporais, mÃ£os e rosto â€“ 411 pontos por frame);  
- **VÃ­deos RGB**;  
- **Labels anotados** com categorias de comportamento.  

---

## ğŸ“Š Como o sistema funciona  

1. **Coleta de dados** (skeleton e vÃ­deos RGB).  
2. **PrÃ©-processamento**: normalizaÃ§Ã£o e padronizaÃ§Ã£o das sequÃªncias.  
3. **Treinamento** de modelos LSTM com dados processados.  
4. **AvaliaÃ§Ã£o** no conjunto de teste com mÃ©tricas (acurÃ¡cia, F1-score, etc.).  
5. **InferÃªncia em tempo real** com feedback adaptativo ao usuÃ¡rio.  

---

## ğŸ“‘ SituaÃ§Ã£o Atual  

- âœ… EstruturaÃ§Ã£o dos dados (skeleton â†’ `.npy`)  
- âœ… DefiniÃ§Ã£o da arquitetura inicial (LSTM)  
- ğŸ”„ ImplementaÃ§Ã£o e avaliaÃ§Ã£o do modelo  
- ğŸ”œ Desenvolvimento da interface interativa (feedback em tempo real)  

---

## âœ¨ Impacto Esperado  

O **FaceSense** busca contribuir para:  

- Monitorar **produtividade e saÃºde** em home office;  
- Evitar **burnout** por excesso de exposiÃ§Ã£o Ã  tela;  
- Melhorar **consciÃªncia corporal e emocional**;  
- Incentivar o **descanso estratÃ©gico**.  
